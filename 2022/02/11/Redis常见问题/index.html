<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Redis常见问题 | boranの小さな巣</title><meta name="keywords" content="Redis"><meta name="author" content="chen-boran"><meta name="copyright" content="chen-boran"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="some of my notes">
<meta property="og:type" content="article">
<meta property="og:title" content="Redis常见问题">
<meta property="og:url" content="http://example.com/2022/02/11/Redis%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/index.html">
<meta property="og:site_name" content="boranの小さな巣">
<meta property="og:description" content="some of my notes">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202203151833185.jpg">
<meta property="article:published_time" content="2022-02-11T12:51:40.000Z">
<meta property="article:modified_time" content="2022-03-18T07:38:56.468Z">
<meta property="article:author" content="chen-boran">
<meta property="article:tag" content="Redis">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202203151833185.jpg"><link rel="shortcut icon" href="/img/favicon.jpg"><link rel="canonical" href="http://example.com/2022/02/11/Redis%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-03-18 15:38:56'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><link rel="stylesheet" href="/clock/css/clock.css"/><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-clock/lib/clock.min.css" /><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="boranの小さな巣" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/favicon.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">56</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">12</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> link</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202203151833185.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">boranの小さな巣</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> link</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Redis常见问题</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-02-11T12:51:40.000Z" title="Created 2022-02-11 20:51:40">2022-02-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-03-18T07:38:56.468Z" title="Updated 2022-03-18 15:38:56">2022-03-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Notes/">Notes</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Redis常见问题"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><hr>
<pre><code>- - 如何解决缓存雪崩？
  - 如何解决缓存穿透？
  - 如何保证缓存与数据库双写时一致的问题？

- # 一、缓存雪崩

- ## 1.1什么是缓存雪崩？

- 回顾一下我们为什么要用缓存(Redis)：

- ![图片](https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202202112044559.webp)为什么要缓存

- 现在有个问题，**如果我们的缓存挂掉了，这意味着我们的全部请求都跑去数据库了**。

- ![图片](https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202202112045056.webp)如果缓存挂掉了，全部请求跑去数据库了

- 在前面学习我们都知道Redis不可能把所有的数据都缓存起来(**内存昂贵且有限**)，所以Redis需要对数据设置过期时间，并采用的是惰性删除+定期删除两种策略对过期键删除。[Redis对过期键的策略+持久化](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&amp;mid=2247484386&amp;idx=1&amp;sn=323ddc84dc851a975530090fcd6e2326&amp;chksm=ebd742e3dca0cbf52bc65d430447e639d81cc13e0ac34613edf464dae3950b10e2e1df74dcc5&amp;token=1834317504&amp;lang=zh_CN&amp;scene=21#wechat_redirect)

- 如果缓存数据**设置的过期时间是相同**的，并且Redis恰好将这部分数据全部删光了。这就会导致在这段时间内，这些缓存**同时失效**，全部请求到数据库中。

- **这就是缓存雪崩**：

- - Redis挂掉了，请求全部走数据库。
  - 对缓存数据设置相同的过期时间，导致某段时间内缓存失效，请求全部走数据库。

- 缓存雪崩如果发生了，很可能就把我们的数据库**搞垮**，导致整个服务瘫痪！

- ## 1.2如何解决缓存雪崩？

- 对于“对缓存数据设置相同的过期时间，导致某段时间内缓存失效，请求全部走数据库。”这种情况，非常好解决：

- - 解决方法：在缓存的时候给过期时间加上一个**随机值**，这样就会大幅度的**减少缓存在同一时间过期**。

- 对于“Redis挂掉了，请求全部走数据库”这种情况，我们可以有以下的思路：

- - 事发前：实现Redis的**高可用**(主从架构+Sentinel 或者Redis Cluster)，尽量避免Redis挂掉这种情况发生。
  - 事发中：万一Redis真的挂了，我们可以设置**本地缓存(ehcache)+限流(hystrix)**，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的)
  - 事发后：redis持久化，重启后自动从磁盘上加载数据，**快速恢复缓存数据**。

- # 二、缓存穿透

- ## 2.1什么是缓存穿透

- 比如，我们有一张数据库表，ID都是从1开始的(**正数**)：

- ![图片](https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202202112046859.webp)随便找了一张数据库表

- 但是可能有黑客想把我的数据库搞垮，每次请求的ID都是**负数**。这会导致我的缓存就没用了，请求全部都找数据库去了，但数据库也没有这个值啊，所以每次都返回空出去。

- &gt; 缓存穿透是指查询一个一定**不存在的数据**。由于缓存不命中，并且出于容错考虑，如果从**数据库查不到数据则不写入缓存**，这将导致这个不存在的数据**每次请求都要到数据库去查询**，失去了缓存的意义。

- ![图片](https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202202112046860.webp)缓存穿透

- **这就是缓存穿透**：

- - 请求的数据在缓存大量不命中，导致请求走数据库。

- 缓存穿透如果发生了，也可能把我们的数据库**搞垮**，导致整个服务瘫痪！

- ## 2.1如何解决缓存穿透？

- 解决缓存穿透也有两种方案：

- - 由于请求的参数是不合法的(每次都请求不存在的参数)，于是我们可以使用布隆过滤器(BloomFilter)或者压缩filter**提前拦截**，不合法就不让这个请求到数据库层！

  - 当我们从数据库找不到的时候，我们也将这个**空对象设置到缓存里边去**。下次再请求的时候，就可以从缓存里边获取了。

  - - 这种情况我们一般会将空对象设置一个**较短的过期时间**。

- 参考资料：

- - 缓存系列文章--5.缓存穿透问题

  - - https://carlosfu.iteye.com/blog/2248185

- # 三、缓存与数据库双写一致

- ## 3.1对于读操作，流程是这样的

- 上面讲缓存穿透的时候也提到了：如果从数据库查不到数据则不写入缓存。

- 一般我们对**读操作**的时候有这么一个**固定的套路**：

- - 如果我们的数据在缓存里边有，那么就直接取缓存的。
  - 如果缓存里没有我们想要的数据，我们会先去查询数据库，然后**将数据库查出来的数据写到缓存中**。
  - 最后将数据返回给请求

- ## 3.2什么是缓存与数据库双写一致问题？

- 如果仅仅查询的话，缓存的数据和数据库的数据是没问题的。但是，当我们要**更新**时候呢？各种情况很可能就**造成数据库和缓存的数据不一致**了。

- - 这里不一致指的是：**数据库的数据跟缓存的数据不一致**

- ![图片](https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202202112046180.webp)数据库和缓存的数据不一致

- 从理论上说，只要我们设置了**键的过期时间**，我们就能保证缓存和数据库的数据**最终是一致**的。因为只要缓存数据过期了，就会被删除。随后读的时候，因为缓存里没有，就可以查数据库的数据，然后将数据库查出来的数据写入到缓存中。

- 除了设置过期时间，我们还需要做更多的措施来**尽量避免**数据库与缓存处于不一致的情况发生。

- ## 3.3对于更新操作

- 一般来说，执行更新操作时，我们会有两种选择：

- - 先操作数据库，再操作缓存
  - 先操作缓存，再操作数据库

- 首先，要明确的是，无论我们选择哪个，我们都希望这**两个操作要么同时成功，要么同时失败**。所以，这会演变成一个**分布式事务**的问题。

- 所以，**如果原子性被破坏了**，可能会有以下的情况：

- - **操作数据库成功了，操作缓存失败了**。
  - **操作缓存成功了，操作数据库失败了**。

- &gt; 如果第一步已经失败了，我们直接返回Exception出去就好了，第二步根本不会执行。

- 下面我们具体来分析一下吧。

- ### 3.3.1操作缓存

- 操作缓存也有两种方案：

- - 更新缓存
  - 删除缓存

- 一般我们都是采取**删除缓存**缓存策略的，原因如下：

- 1. 高并发环境下，无论是先操作数据库还是后操作数据库而言，如果加上更新缓存，那就**更加容易**导致数据库与缓存数据不一致问题。(删除缓存**直接和简单**很多)
  2. 如果每次更新了数据库，都要更新缓存【这里指的是频繁更新的场景，这会耗费一定的性能】，倒不如直接删除掉。等再次读取时，缓存里没有，那我到数据库找，在数据库找到再写到缓存里边(体现**懒加载**)

- 基于这两点，对于缓存在更新时而言，都是建议执行**删除**操作！

- ### 3.3.2先更新数据库，再删除缓存

- 正常的情况是这样的：

- - 先操作数据库，成功；
  - 再删除缓存，也成功；

- 如果原子性被破坏了：

- - 第一步成功(操作数据库)，第二步失败(删除缓存)，会导致**数据库里是新数据，而缓存里是旧数据**。
  - 如果第一步(操作数据库)就失败了，我们可以直接返回错误(Exception)，不会出现数据不一致。

- 如果在高并发的场景下，出现数据库与缓存数据不一致的**概率特别低**，也不是没有：

- - 缓存**刚好**失效
  - 线程A查询数据库，得一个旧值
  - 线程B将新值写入数据库
  - 线程B删除缓存
  - 线程A将查到的旧值写入缓存

- 要达成上述情况，还是说一句**概率特别低**：

- &gt; 因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，**而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存**，所有的这些条件都具备的概率基本并不大。

- 对于这种策略，其实是一种设计模式：`Cache Aside Pattern`

- ![图片](https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202202112044375.webp)先修改数据库，再删除缓存

- **删除缓存失败的解决思路**：

- - 将需要删除的key发送到消息队列中
  - 自己消费消息，获得需要删除的key
  - **不断重试删除操作，直到成功**

- ### 3.3.3先删除缓存，再更新数据库

- 正常情况是这样的：

- - 先删除缓存，成功；
  - 再更新数据库，也成功；

- 如果原子性被破坏了：

- - 第一步成功(删除缓存)，第二步失败(更新数据库)，数据库和缓存的数据还是一致的。
  - 如果第一步(删除缓存)就失败了，我们可以直接返回错误(Exception)，数据库和缓存的数据还是一致的。

- 看起来是很美好，但是我们在并发场景下分析一下，就知道还是有问题的了：

- - 线程A删除了缓存
  - 线程B查询，发现缓存已不存在
  - 线程B去数据库查询得到旧值
  - 线程B将旧值写入缓存
  - 线程A将新值写入数据库

- 所以也会导致数据库和缓存不一致的问题。

- **并发下解决数据库与缓存不一致的思路**：

- - 将删除缓存、修改数据库、读取缓存等的操作积压到**队列**里边，实现**串行化**。

- ![图片](https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202202112044508.webp)将操作积压到队列中

- ## 3.4对比两种策略

- 我们可以发现，两种策略各自有优缺点：

- - 先删除缓存，再更新数据库

  - - 在高并发下表现不如意，在原子性被破坏时表现优异

  - 先更新数据库，再删除缓存(`Cache Aside Pattern`设计模式)

  - - 在高并发下表现优异，在原子性被破坏时表现不如意
</code></pre>
<h2 id="3-5其他保障数据一致的方案与资料"><a href="#3-5其他保障数据一致的方案与资料" class="headerlink" title="3.5其他保障数据一致的方案与资料"></a>3.5其他保障数据一致的方案与资料</h2><p>可以用<strong>databus</strong>或者阿里的<strong>canal监听binlog</strong>进行更新。</p>
<p>参考资料：</p>
<ul>
<li><p>缓存更新的套路</p>
</li>
<li><ul>
<li><a target="_blank" rel="noopener" href="https://coolshell.cn/articles/17416.html">https://coolshell.cn/articles/17416.html</a></li>
</ul>
</li>
<li><p>如何保证缓存与数据库双写时的数据一致性？</p>
</li>
<li><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-consistence.md">https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-consistence.md</a></li>
</ul>
</li>
<li><p>分布式之数据库和缓存双写一致性方案解析</p>
</li>
<li><ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/48334686">https://zhuanlan.zhihu.com/p/48334686</a></li>
</ul>
</li>
<li><p>Cache Aside Pattern</p>
</li>
<li><ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/z50l2o08e2u4aftor9a/article/details/81008933">https://blog.csdn.net/z50l2o08e2u4aftor9a/article/details/81008933</a></li>
</ul>
</li>
</ul>
<p>作者：走马观花AA<br>链接：<a target="_blank" rel="noopener" href="https://www.nowcoder.com/discuss/864641?type=all&amp;order=recall&amp;pos=&amp;page=1&amp;ncTraceId=&amp;channel=-1&amp;source_id=search_all_nctrack&amp;gio_id=B72BE11AC5CE4285D6262E3B40B306F9-1647494144339">https://www.nowcoder.com/discuss/864641?type=all&amp;order=recall&amp;pos=&amp;page=1&amp;ncTraceId=&amp;channel=-1&amp;source_id=search_all_nctrack&amp;gio_id=B72BE11AC5CE4285D6262E3B40B306F9-1647494144339</a><br>来源：牛客网</p>
<p>分布式缓存 </p>
<p> 缓存好处：高性能 + 高并 </p>
<p>​    </p>
<p> 数据库查询耗费了800ms，其他用户对同一个数据再次查询 ，假设该数据在10分钟以内没有变化过，并且 10 分钟之内有 1000 个用户 都查询了同一数据，10 分钟之内，那 1000 每个用户，每个人查询这个数据都感觉很慢 800ms </p>
<p> 比如 ：某个商品信息，在 一天之内都不会改变，但是这个商品每次查询一次都要耗费2s，一天之内被浏览 100W次 </p>
<p> mysql 单机也就 2000qps,缓存单机轻松几万几十万qps,单机 承载并发量是 mysql 单机的几十倍。 </p>
<p> 如果感觉小编写得不错，请素质三连：点赞+转发+关注。我会努力写出更好的作品分享给大家。更多<a target="_blank" rel="noopener" href="https://docs.qq.com/doc/DVGJkS1lRRWdrV3hk">学习资料</a>小编已打包好，可以找我领取哦！领取方式：私信回复暗号<strong>【333】</strong>即可免费领取更多完整版资料。 </p>
<p> 高并发 </p>
<p> 在中午高峰期，有 100W 个用户访问系统 A，每秒有 4000 个请求去查询数据库，数据库承载每秒 4000 个请求会宕机，加上缓存后，可以 3000 个请求走缓存 ，1000 个请求走数据库。 </p>
<p> 缓存是走内存的，内存天然可以支撑4w/s的请求，数据库（基于磁盘）一般建议并发请求不要超过 2000/s </p>
<p> 缓存不良后果 </p>
<p> 缓存与数据库双写不一致 </p>
<p> 缓存雪崩 </p>
<p> 缓存穿透 </p>
<p> 缓存并发竞争 </p>
<p> Redis 线程模型 </p>
<p> <a href="">redis</a> 单线程 ，memcached 多线程 </p>
<p> <a href="">redis</a> 是单线程 nio 异步线程模型 </p>
<p> Redis 和 Memcached 区别 </p>
<p> Redis 支持服务器端的数据操作：Redis比Memcached来说，拥有更多的数据结构和并支持更丰富的数据操作，通常在Memcached里，你需要将数据拿到客户端来进行类似的修改再set回去。这大大增加了网络 IO 的次数和数据体积。在Redis中，这些复杂的操作通常和一般的GET/SET一样高效。所以，如果需要缓存能支持更复杂的结构和操作，那么Redis会是不错的选择 </p>
<p> 集群模式：memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据，但是 Redis 目前是原生支持 cluster模式的 </p>
<p> Redis 单线程模型 </p>
<p> 一个线程+一个队列 </p>
<p> <a href="">redis</a> 基于 reactor 模式开发了网络事件处理器，这个处理器叫做文件事件处理器，file event handler，这个文件事件处理器是单线程的，所以<a href="">redis</a> 是单线程的模型，采用 io多路复用机制同时监听多个 socket,根据socket上的事件来选择对应的事件处理器来处理这个事件。 </p>
<p> 文件事件处理器包含：多个 socket,io多路复用程序，文件事件分派器，事件处理器（命令请求处理器、命令恢复处理器、连接应答处理器） </p>
<p> 文件事件处理器是单线程的，通过 io 多路复用机制监听多个 socket，实现高性能和线程模型简单性 </p>
<p> 被监听的 socket 准备好执行 accept,read,write,close等操作的时候，会产生对应的文件事件，调用之前关联好的时间处理器处理 </p>
<p> 多个 socket并发操作，产生不同的文件事件，i/o多路复用会监听多个socket，将这些 socket放入一个队列中排队。事件分派器从队列中取出socket给对应事件处理器。 </p>
<p> 一个socket时间处理完后，事件分派器才能从队列中拿到下一个socket，给对应事件处理器来处理。 </p>
<p> 文件事件： </p>
<p> AE_READABLE 对应 socket变得可读（客户端对<a href="">redis</a>执行 write操作） </p>
<p> AE_WRITABLE 对应 socket 变得可写（客户端对 <a href="">redis</a>执行 read操作） </p>
<p> I/O 多路复用可以同时监听AE_REABLE和 AE_WRITABLE ，如果同时达到则优先处理 AE_REABLE 时间 </p>
<p> 文件事件处理器： </p>
<p> 连接应答处理器 对应 客户端要连接 <a href="">redis</a> </p>
<p> 命令请求处理器 对应 客户端写数据到 <a href="">redis</a> </p>
<p> 命令恢复处理器 对应 客户端从 <a href="">redis</a> 读数据 </p>
<p> 流程： </p>
<p> <a href="">redis</a> 初始化时，会将连接应答处理器跟 AE_READABLE事件关联 </p>
<p> 客户端对 <a href="">redis</a> 发起连接，产生一个 AE_READABLE 事件 </p>
<p> 连接应答处理器处理客户端 AE_READABLE 事件，创建客户端对应的 socket，同时将这个 socket的 AE_READABLE 事件和命令请求处理器关联 </p>
<p> 客户端对 <a href="">redis</a> 发起读请求，会在 socket上产生一个 AE_READABLE 事件 </p>
<p> 绑定 AE_READABLE 事件的命令请求处理器会从 socket 中读取请求相关数据，执行对应操作，当执行完毕后，将 socket的 AE_WRITABLE 事件跟命令回复处理器关联 </p>
<p> 当客户端这边准备好读取响应时，会在 socket上产生一个AE_WRITABLE事件 </p>
<p> 绑定 AE_WRITABLE 事件的命令回复处理器将准备好的响应数据写入 socket，供客户端来读取 </p>
<p> 命令回复处理器写完后，删掉 socket的 AE_WRITABLE 事件和命令回复处理器的绑定关系 </p>
<p> Redis 单线程模型效率高 </p>
<p> 一秒钟可以处理几万个请求 </p>
<p> 非阻塞 I/O 多路复用机制（不处理事件，只轮询请求压入队列） </p>
<p> 纯内存操作（操作只有几微秒） </p>
<p> 单线程反而 避免了多线程频繁上下文切换的问题 </p>
<p> Redis 数据类型 </p>
<p> string </p>
<p> 普通的 set,get kv缓存 </p>
<p> hash </p>
<p> 类型 map结构，比如一个对象（没有嵌套对象）缓存到 <a href="">redis</a>里面，然后读写缓存的时候，可以直接操作hash的字段（比如把 age 改成 21，其他的不变） </p>
<p> key=150 </p>
<p> value = { </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;id&quot;:150, &quot;name&quot;:&quot;zhangsan&quot;, &quot;age&quot;:20</span><br></pre></td></tr></table></figure>

<p> 有序列表 ，元素可以重复 </p>
<p> 可以通过 list 存储一些列表型数据结构，类似粉丝列表，文章评论列表。 </p>
<p> 例如：微信大 V的粉丝，可以以 list 的格式放在 <a href="">redis</a> 里去缓存 </p>
<p> key=某大 V value=[zhangsan,lisi,wangwu] </p>
<p> 比如 lrange 可以从某个元素开始读取多少个元素，可以基于 list 实现分页查询功能，基于 <a href="">redis</a>实现高性能分页，类似<a href="">微博</a>下来不断分页东西。 </p>
<p> 可以搞个简单的消息队列，从 list头怼进去（lpush），list尾巴出来 (brpop) </p>
<p> set </p>
<p> 无序集合，自动去重 </p>
<p> 需要对一些数据快速全局去重，（当然也可以基于 HashSet，但是单机） </p>
<p> 基于 set 玩差集、并集、交集的操作。比如：2 个人的粉丝列表整一个交集，看看 2 个人的共同好友是谁？ </p>
<p> 把 2 个大 V 的粉丝都放在 2 个 set中，对 2 个 set做交集（sinter） </p>
<p> sorted set </p>
<p> <a href="">排序</a>的 set，去重但是可以<a href="">排序</a>，写进去的时候给一个分数，自动根据分数<a href="">排序</a> </p>
<p> 排行榜： </p>
<p> 将每个用户以及其对应的分数写入进去 </p>
<p> zadd board score username </p>
<p> zrevrange board 0 99 可以获取排名前 100 的用户 </p>
<p> zrank board username 可以看到用户在排行榜里的排名 </p>
<p> 例如： </p>
<p> zadd board 85 zhangsan </p>
<p> zadd board 72 wangwu </p>
<p> zadd board 96 lis </p>
<p> zadd board 62 zhaoliu </p>
<p> 自动<a href="">排序</a>为： </p>
<p> 96 lisi </p>
<p> 85 zhangsan </p>
<p> 72 wangwu </p>
<p> 62 zhaoliu </p>
<p> 获取排名前 3 的用户 ： zrevrange board 0 3 </p>
<p> 96 lisi </p>
<p> 85 zhangsan </p>
<p> 72 wangwu </p>
<p> 查看zhaoliu的排行 ：zrank board zhaoliu 返回 4 </p>
<p> Redis 过期策略 </p>
<p> 内存是宝贵的，磁盘是廉价的 </p>
<p> 给key设置过期时间后，<a href="">redis</a>对这批key是定期删除+惰性删除 </p>
<p> 定期删除： </p>
<p> <a href="">redis</a> 默认每隔 100ms随机抽取一些设置了过期时间的 key，检查其是否过期了，如果过期就删除。 </p>
<p> 注意：<a href="">redis</a>是每隔100ms随机抽取一些 key来检查和删除，而不是遍历所有的设置过期时间的key（否则CPU 负载会很高，消耗在检查过期 key 上） </p>
<p> 惰性删除： </p>
<p>  获取某个key的时候， <a href="">redis</a> 会检查一下，这个key如果设置了过期时间那么是否过期，如果过期了则删除。 </p>
<p> 如果定期删除漏掉了许多过期key，然后你也没及时去查，也没走惰性删除，如果大量过期的key堆积在内存里，导致 <a href="">redis</a> 内存块耗尽，则走内存淘汰机制。 </p>
<p> 内存淘汰策略： </p>
<p> noeviction:当内存不足以容纳新写入数据时，新写入操作直接报错（没人用） </p>
<p> allkeys-LRU: 当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（最常用） </p>
<p> allkeys-random: 当内存不足以容纳新写入数据时，在键空间中，随机移除某个 key，(没人用) </p>
<p> volatile-lru:当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key(不合适) </p>
<p> volatile-ttl:当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 key 优先移除(不合适) </p>
<p> LRU <a href="">算法</a>： </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">package com.mousycoder.mycode; import java.util.LinkedHashMap; import java.util.Map; /**</span><br><span class="line">* @version 1.0</span><br><span class="line">* @author: mousycoder</span><br><span class="line">* @date: 2019/10/31 17:55</span><br><span class="line">*/ public class lruCache&lt;K,V&gt; extends LinkedHashMap&lt;K,V&gt; &#123; private final int CACHE_SIZE; public LRUCache( int cacheSize) &#123; super((int)Math.ceil(cacheSize / 0.75) + 1 ,0.75f,true); this.CACHE_SIZE = cacheSize;</span><br><span class="line">&#125; @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123; return size() &gt; CACHE_SIZE;</span><br><span class="line">&#125; public static void main(String[] args) &#123;</span><br><span class="line">LRUCache&lt;integer,Integer&gt; lruCache = new LRUCache&lt;&gt;(10); for (int i = 0; i &lt; 15; i++) &#123;</span><br><span class="line">lruCache.put(i,i);</span><br><span class="line">&#125;</span><br><span class="line">Integer integer1 = lruCache.get(0); for (Integer integer : lruCache.keySet()) &#123;</span><br><span class="line">System.out.println(integer);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> Redis 高并发和高可用 </p>
<p> 缓存架构（多级缓存架构、热点缓存） </p>
<p> <a href="">redis</a> 高并发瓶颈在单机，读写分离，一般是支撑读高并发，写请求少，也就 一秒一两千，大量请求读，一秒钟二十万次。 </p>
<p> 主从架构 </p>
<p> 一主多从，主负责写，将数据同步复制到其他 slave节点，从节点负责读，所有读的请求全部走从节点。主要是解决读高并发。、 </p>
<p> 主从架构-&gt;读写分离-&gt;支撑10W+读QPS架构 </p>
<p> Redis Replication </p>
<p> master-&gt;slave 复制，是异步的 </p>
<p> 核心机制： </p>
<p> <a href="">redis</a> 采用异步方式复制数据到 slave 节点 </p>
<p> 一个 master node是可以配置多个 slave node的 </p>
<p> slave node也可以连接其他的 slave node </p>
<p> slave node 做复制的时候，是不会 block master node的正常工作 </p>
<p> slave node 在做复制的时候，也不会 block对自己的查询操作，它会用旧的数据集来提供服务。但是复制完成时，需要删除旧数据集，加载新的数据集，这个时候就会暂停对外服务了。 </p>
<p> slave node 主要用来进行横向扩容，做读写分离，扩容 slave node 可以提高读的吞吐量 </p>
<p> master持久化对主从架构的意义： </p>
<p> 如果开启了主从架构，一定要开启 master node的持久化，不然 master宕机重启数据是空的，一经复制，slave的数据也丢了 </p>
<p> 主从复制原理： </p>
<p> 第一次启动或者断开重连情况： </p>
<p> 当启动一个 slave node的时候，它会发送一个 PSYNC 命令给 master node </p>
<p> master 会触发一次 full resynchronization （如果不是第一次连接，master 只会复制给 slave 部分缺少的数据，从backlog里找） </p>
<p> master会启动一个后台线程，开始生成一份 RDB 快照（ bgsave,也可以直接在内存中创建），同时将从客户端收到的所有写命令缓存在内存中。RDB 文件生成完毕之后，master会将这个RDB发送给slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中。然后 master会将内存中缓存的写命令发送给 slave,slave也会同步这些数据（slave如果跟 master网络故障，断开连接，会自动重连，master如果发现有多个 slave 来重新连接，仅仅只会启动一个 RDB save 操作，用一份数据服务所有 slave node） </p>
<p> 正常情况下： </p>
<p> master 来一条数据，就异步给 slave </p>
<p> Redis高可用性 </p>
<p> 全年 99.99%的时间，都是出于可用的状态，那么就可以称为高可用性 </p>
<p> <a href="">redis</a> 高可用架构叫故障转移，failover，也可以叫做主备切换，切换的时间不可用，但是整体高可用。 </p>
<p> sentinal node(哨兵) </p>
<p> Sentinal </p>
<p> 作用： </p>
<p> 集群监控，负责监控 <a href="">redis</a> master 和 slave进程是否正常 </p>
<p> 消息通知，如果某个 <a href="">redis</a> 实例有故障，那么哨兵负责发送消息作为报警通知给管理员 </p>
<p> 故障转移，如果 master 挂掉，会自动转移到 slave </p>
<p> 配置中心，如果故障转移了，通知 client 客户端新的 master地址 </p>
<p> 两节点哨兵集群 </p>
<p> quorum = 1 （代表哨兵最低个数可以尝试故障转移，选举执行的哨兵） </p>
<p> master 宕机，只有 S2 存活，因为 quorum =1 可以尝试故障转移，但是没达到 majority =2 （最低允许执行故障转移的哨兵存活数）的标准，无法执行故障转移 </p>
<p> 三节点哨兵集群（经典） </p>
<p> 如果 M1 宕机了，S2,S3 认为 master宕机，选举一个执行故障转移，因为 3 个哨兵的 majority = 2，所以可以执行故障转移 </p>
<p> Redis 主从 + 哨兵 </p>
<p> 丢数据： </p>
<p> master内存中数据异步同步到 slave master 就挂掉了,丢掉了 master 内存中的数据 </p>
<p> 脑裂，某个 master 所在机器突然脱离了正常的网络，其他 slave机器不能连接，但是实际上 master还在运行，哨兵认为 master 宕机，选举 slave为master，此时集群里有 2 个 master, client还没来得及切换到新的master，还继续写在旧的 master上，数据丢了，此时旧的 master再次恢复，被被作为一个 slave 挂到新的 master 上，自己的数据被清空 （脑裂，大脑一分为 2，同时指挥同一个人） </p>
<p> 解决方案： </p>
<p> min-slaves-max-lag 10 （至少一个 slave同步的延迟不能超过 10s） 减少异步复制的数据丢失，发现slave复制数据和 ack延时过长，拒绝写入，减少同步数据损失。让client做降级写到本地磁盘里和限流，或者先暂存到消息队列，然后重新发回 master </p>
<p> min-slaves-to-write 1 减少脑裂带来的数据丢失，最多损失 10 s数据，假设master 不能继续给 slave发送数据，并且 slave 10s没给自己的 ack消息，直接拒绝客户端写请求，同时 client做降写到本地磁盘、限流，或者先暂存到消息队列，然后重新发回 master </p>
<p> 哨兵 </p>
<p> sdown 主观宕机，哨兵觉得一个 master 宕机（ping 超过了 </p>
<p> is-master-down-after-milliseconds毫秒数） </p>
<p> odown 客观宕机，quorum数量的哨兵都觉得 master宕机 </p>
<p> 哨兵互相感知通过 <a href="">redis</a>的 pub/sub系统，每隔 2 秒往同一个 channel里发消息（自己的 host,ip,runid），其他哨兵可以消费这个消息 </p>
<p> 以及同步交换master的监控信息。 </p>
<p> 哨兵确保其他slave修改master信息为新选举的master </p>
<p> 当一个 master被认为 odown &amp;&amp; marjority哨兵都同意，那么某个哨兵会执行主备切换，选举一个slave成为master（考虑 1. 跟master断开连接的时长 2. slave 优先级 3.复制 offset 4. runid） </p>
<p> 选举<a href="">算法</a>： </p>
<p> 如果slave跟master断开连接已经超过 down-after-milliseconds * 10 + master宕机时间，则放弃 </p>
<p> 按 slave 优先级<a href="">排序</a> ，slave-priority 越小越靠前 </p>
<p> replica offset ，哪个slave复制越多的数据，越靠前 </p>
<p> runid 越小，越靠前 </p>
<p> quorum 数量哨兵认为odown-&gt;选举一个哨兵切换-&gt;获得 majority哨兵的授权（quorum &lt; majority 需要 majority个哨兵授权，quorum &gt;= majority 需要 quorum 哨兵授权） </p>
<p> 第一个选举出来的哨兵切换失败了，其他哨兵等待 failover-time之后，重新拿confiuration epoch做为新的version 切换，保证拿到最新配置，用于 configuration传播（通过 pu/sub消息机制，其他哨兵对比 version 新旧更新 master配置） </p>
<p> Redis 优化方案 </p>
<p> 高并发：主从架构 </p>
<p> 高容量：Redis集群，支持每秒几十万的读写并发 </p>
<p> 高可用：主从+哨兵 </p>
<p> Redis 持久化 </p>
<p> 持久化的意义在于故障恢复数据备份（到其他服务器）+故障恢复（遇到灾难，机房断电，电缆被切） </p>
<p> RDB 对 Redis 中的数据执行周期性的持久化。 </p>
<p> AOF 机制，每条写命令作为日志，以 append-only模式写入一个日志文件总，在 <a href="">redis</a>重启的时候，可以通过回放AOF日志中的写入指令来重新构建整个数据集 </p>
<p> AOF 只有一个，Redis 中的数据是有一定限量的，内存大小是一定的,AOF 是存放写命令的，当大到一定的时候，AOF 做 rewrite 操作，就会基于当时 <a href="">redis</a> 内存中的数据，来重新构造一个更小的 AOF 文件，然后将旧的膨胀很大的文件给删掉，AOF 文件一直会被限制在和Redis内存中一样的数据。AOF同步间隔比 RDB 小，数据更完整 </p>
<p> RDB </p>
<p> 优点： </p>
<p> RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 <a href="">redis</a> 的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去，RDB 做冷备，生成多个文件，每个文件都代表某一个时刻的完整的数据快照，AOF 也可以做冷备，只有一个文件，每隔一定时间去 copy一份这个文件出来。 RDB 做冷备，由Redis控制固定时长去生成快照文件，比较方便。AOF，需要自己写脚本定时控制。 </p>
<p> RDB 对 <a href="">redis</a>对外提供的读写服务，影响非常小，可以让 <a href="">redis</a> 保持高性能，因为 <a href="">redis</a> 主进程只需要 fork一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化 </p>
<p> 相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 <a href="">redis</a> 进程，更加快速 </p>
<p> 缺点： </p>
<p> 如果想要在 <a href="">redis</a>故障时，尽可能少丢数据，那么 RDB 没有 AOF 好，一般 RDB 数据快照，都是间隔 5 分钟，或者更长的时候生成一次，这个时候就得接受一旦 <a href="">redis</a> 进程宕机，那么会丢失最近 5 分钟数据 </p>
<p> RDB 每次在 fork子进程来执行 RDB 快早数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，甚至数秒（RDB 生成间隔不要太长） </p>
<p> AOF 存放的指令日志，数据恢复的时候，需要回放执行所有指令日志，RDB 就是一份数据文件，直接加载到内存中。 </p>
<p> AOF </p>
<p> 优点： </p>
<p> 更好保护数据不丢失，后台线程 fsync 操作，最多丢失一秒钟数据，保证 os cache中的数据写入磁盘中 </p>
<p> AOF 用 append-only 模式，没有磁盘寻址开销，写入性能非常高，文件不容易损坏。 </p>
<p> AOF 日志过大的时候，后台 rewrite log时候，老的日志文件照常写入，新的merge后的日志文件 ready的时候，再交换新老日志文件 </p>
<p> 适合灾难性恢复，某人不小心 flushall清空所有数据，只要后台 rewrite还没发生，那么可以立刻拷贝 AOF 文件，将最后一条 flushall命令给删了，然后再将该 AOF 文件放回去，可以通过恢复机制，自动恢复所有数据 </p>
<p> 缺点： </p>
<p> AOF 日志文件比 RDB 数据快照文件大 </p>
<p> 降低 Redis的写 QPS </p>
<p> AOF 复杂，Bug多 </p>
<p> 数据恢复比较慢 </p>
<p> 最佳方案 </p>
<p> AOF 来保证数据不丢失，RDB 做不同时间的冷备 </p>
<p> Redis Cluster </p>
<p> 支持 N 个 Redis master node,每个 master node挂载多个 slave node </p>
<p> 多master + 读写分离 + 高可用 </p>
<p> 数据量很少，高并发 -&gt; replication + sentinal 集群 </p>
<p> <a href="">海量数据</a> + 高并发 + 高可用 -&gt; <a href="">redis</a> cluster </p>
<p> 分布式<a href="">算法</a> </p>
<p> hash<a href="">算法</a>-&gt;一致性 hash <a href="">算法</a>-&gt; <a href="">redis</a> cluster-&gt;hash slot<a href="">算法</a> </p>
<p> <a href="">redis</a> cluster :自动对数据进行分片，每个 master 上放一部分数据，提供内置的高可用支持，部分master不可用时，还是可以继续工作 </p>
<p> cluster bus 通过 16379进行通信，故障检测，配置更新，故障转移授权，另外一种二进制协议，主要用于节点间进行高效数据交换，占用更少的网络带宽和处理时间 </p>
<p> hash<a href="">算法</a> </p>
<p> key进行hash，然后对节点数量取模，最大问题只有任意一个 master 宕机，大量数据就要根据新的节点数取模，会导致大量缓存失效。 </p>
<p> 一致性 hash <a href="">算法</a> </p>
<p> key进行hash，对应圆环上一个点，顺时针寻找距离最近的一个点。保证任何一个 master 宕机，只受 master 宕机那台影响，其他节点不受影响，此时会瞬间去查数据库。 </p>
<p> 缓存热点问题： </p>
<p> 可能集中在某个 hash区间内的值特别多，那么会导致大量的数据都涌入同一个 master 内，造成 master的热点问题，性能出现瓶颈。 </p>
<p> 解决方法： </p>
<p> 给每个 master 都做了均匀分布的虚拟节点，这样每个区间内大量数据都会均匀的分布到不同节点内，而不是顺时针全部涌入到同一个节点中。 </p>
<p> Hash Slot<a href="">算法</a> </p>
<p> <a href="">redis</a> cluster 有固定 16384 个 hash slot,对每个key计算 CRC16 值，然后对16384取模，可以获取 key对应的 hash slot </p>
<p> <a href="">redis</a> cluster 中每个 master 都会持有部分 slot ,当一台 master 宕机时候，会最快速度迁移 hash slot到可用的机器上（只会短暂的访问不到） </p>
<p> 走同一个 hash slot 通过 hash tag实现 </p>
<p> Redis Cluster 核心 </p>
<p> 基础通信 </p>
<p> 通过 gossip 协议通信（小道留言，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其他节点，让其他节点也进行元数据的变更） </p>
<p> 集群元数据：包括 hashslot-&gt;node之间的映射表关系，master-&gt;slave之间的关系，故障的信息 </p>
<p> 集群元数据集中式存储（storm），底层基于zoo<a href="">keep</a>er（分布式协调中间件）集群所有元数据的维护。好处：元数据的更新和读取，时效性好，一旦变更，其他节点立刻可以感知。缺点：所有元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。 </p>
<p> goosip: 好处：元数据的更新比较分散，有一定的延时，降低了压力。缺点：更新有延时，集群的一些操作会滞后。（reshared操作时configuration error） </p>
<p> 10000 端口 </p>
<p> 自己提供服务的端口号+ 10000 ，每隔一段时间就会往另外几个节点发送ping消息，同时其他几点接收到ping之后返回pong </p>
<p> 交换的信息 </p>
<p> 故障信息，节点的增加和移除， hash slot 信息 </p>
<p> gossip协议 </p>
<p> meet:某个节点发送 meet给新加入的节点，让新节点加入集群中，然后新节点就会开始于其他节点进行通信 </p>
<p> ping:每个节点都会频繁给其他节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据 </p>
<p> ping:返回ping和meet，包含自己的状态和其他信息 </p>
<p> fail:某个节点判断另一个节点fail之后，就发送 fail 给其他节点，通知其他节点，指定的节点宕机了 </p>
<p> ping消息 </p>
<p> ping 很频繁，且携带元数据，会加重网络负担 </p>
<p> 每个节点每秒会执行 10 次 ping，每次选择 5 个最久没有通信的其他节点 </p>
<p> 当如果发现某个节点通信延迟达到了 cluster_node_timeout /2 ，那么立即发送 ping， 避免数据交换延迟过长，落后时间太长（2 个节点之间 10 分钟没有交换数据，整个集群处于严重的元数据不一致的情况）。 </p>
<p> 每次ping，一个是带上自己的节点信息，还有就是带上1/10其他节点的信息，发送出去，进行数据交换 </p>
<p> 至少包含 3 个其他节点信息，最多包含总节点-2 个其他节点的信息 </p>
<p> JRedis原理 </p>
<p> 请求重定向 </p>
<p> 客户端发送到任意一个<a href="">redis</a>实例发送命令，每个<a href="">redis</a>实例接受到命令后，都会计算key对应的hash slot，如果在本地就本地处理，否则返回moved给客户端，让客户端进行重定向 （<a href="">redis</a>-cli -c） </p>
<p> hash slot </p>
<p> 通过tag指定key对应的slot,同一个 tag 下的 key，都会在一个 hash slot中，比如 set key1:{100} 和 set key2:{100} </p>
<p> smart jedis </p>
<p> 本地维护一份hashslot-&gt;node的映射表。 </p>
<p> JedisCluster 初始化的时候，随机选择一个 node，初始化 hashslot-&gt;node 映射表，同时为每个节点创建一个JedisPool连接池，每次基于JedisCluster执行操作，首先JedisCluster都会在本地计算key的hashslot，然后再本地映射表中找到对应的节点，如果发现对应的节点返回moved，那么利用该节点的元数据，更新 hashslot-&gt;node映射表（重试超过 5 次报错） </p>
<p> hashslot迁移和ask重定向 </p>
<p> hash slot正在迁移，那么会返回ask 重定向给jedis,jedis 接受到ask重定向之后，，会重定向到目标节点去执行 </p>
<p> 高可用性和主备切换原理 </p>
<p> 判断节点宕机： </p>
<p> 如果一个节点认为另外一个节点宕机了， 就是pfail,主观宕机 </p>
<p> 如果多个节点都认为另外一个节点宕机了，那么就是fail，客观宕机（跟哨兵原理一样） </p>
<p> 在cluster-node-timeout内，某个节点一直没有返回 pong,那么就被认为是 pfail </p>
<p> 如果一个节点认为某个节点pfail了，那么会在gossip消息中，ping给其他节点，如果超过半数的节点认为pfail了，那么就会变成fail。 </p>
<p> 从节点过滤： </p>
<p> 对宕机的 mster node ，从其所有的 slave node中，选择一个切换成 master node </p>
<p> 检查每个 slave node与master node断开连接的时间，如果超过了cluster-node-timeout * </p>
<p> cluster-slave-validity-factor，那么就没资格切换成 master（和哨兵一致） </p>
<p> 从节点选举： </p>
<p> 每个从节点，根据自己对 master 复制数据的 offset，设置一个选举时间，offset越大（复制数据越多）的从节点，选举时间越靠前，所有的 master node 开始投票，给要进行选举的 slave进行投票，如果大部分 master node(N/2 +1) 都投票给某个从节点，那么选举通过，从节点执行主备切换，从节点切换成主节点 </p>
<p> 总结：和哨兵很像，直接集成了 replication 和 sentinal </p>
<p> 缓存雪崩 </p>
<p> 方案： </p>
<p> 事前：保证 <a href="">redis</a> 集群高可用性 （主从+哨兵或 <a href="">redis</a> cluster），避免全盘崩溃 </p>
<p> 事中：本地 ehcache 缓存 + hystrix 限流（保护数据库） &amp; 降级，避免 MySQL被打死 </p>
<p> 事后： <a href="">redis</a>持久化，快速恢复缓存数据，继续分流高并发请求 </p>
<p> 限制组件每秒就 2000 个请求通过限流组件进入数据库，剩余的 3000 个请求走降级，返回一些默认 的值，或者友情提示 </p>
<p> 好处 ： </p>
<p> 数据库绝对不会死，确保了每秒只会过去 2000 个请求 </p>
<p> 只要数据库不死，对于用户来说 2/5的请求可以被处理 </p>
<p> 系统没死，用户多点几次可能就刷出来了 </p>
<p> 缓存穿透 </p>
<p> 4000 个请求黑客攻击请求数据库里没有的数据 </p>
<p> 解决方案：把黑客查数据库中不存在的数据的值，写到缓存中，比如： set -999 UNKNOWN </p>
<p> 缓存与数据库双写一致性 </p>
<p> cache aside pattern </p>
<p> 读的时候，先读缓存，缓存没有，就读数据库，然后取出数据后放入缓存，同时返回响应 </p>
<p> 更新的时候，删除缓存，更新数据库 </p>
<p> 为什么不更新缓存： </p>
<p> 更新缓存代价太高（更新 20 次，只读 1 次），lazy思想，需要的时候再计算，不需要的时候不计算 </p>
<p> 修改数据库成功，删除缓存失败，导致数据库是新的数据，缓存中是旧的数据 </p>
<p> 方案：先删除缓存，再修改数据库 </p>
<p> 修改数据库还没修改完，同时又有查询请求，把旧的数据放到缓存中（高并发，每秒并发读几万，每秒只要有数据更新请求，就可能出现数据库+缓存不一致情况） </p>
<p> 方案：写，读路由到相同的一个内存队列（唯一标识，hash，取模）里，更新和读操作进行串行化（后台线程异步执行队列串行化操作），（队列里只放一个更新查询操作即可，多余的过滤掉，内存队列里没有该数据更新操作，直接返回 ）有该数据更新操作则轮询取缓存值，超时取不到缓存值，直接取一次数据库的旧值 </p>
<p> TP 99 意思是99%的请求可以在200ms内返回 </p>
<p> 注意点：多个商品的更新操作都积压在一个队列里面（太多操作积压只能增加机器），导致读请求发生大量的超时，导致大量的读请求走数据库 </p>
<p> 一秒 500 写操作，每200ms，100 个写操作，20 个内存队列，每个队列积压 5 个写操作，一般在20ms完成 </p>
<p> Redis 并发竞争问题 </p>
<p> 方案：分布式锁 + 时间戳比较 </p>
<p> Redis 集群部署架构 </p>
<p> 10台机器，5 主 5 从，每个节点QPS 5W ，一共 25W QPS（Redis cluster 32G + 8 核 ，Redis 进程不超过 10G）总内存 50g，每条数据10kb，10W 条数据1g，200W 条数据 20G，占用总内存不到50%，目前高峰期 3500 QPS</p>
<p>4.2 Redis</p>
<p>作者：Guide哥。</p>
<p><strong>介绍</strong><strong>:</strong> Github 70k Star 项⽬ <strong>JavaGuide</strong>（公众号同名） 作者。每周都会在公众号更新⼀些⾃⼰原</p>
<p>创⼲货。公众号后台回复“1”领取Java⼯程师必备学习资料+⾯试突击pdf。</p>
<p>4.2.1 redis <strong>简介</strong></p>
<p>简单来说 redis 就是⼀个数据库，不过与传统数据库不同的是 redis 的数据是存在内存中的，所以读</p>
<p>写速度⾮常快，因此 redis 被⼴泛应⽤于缓存⽅向。另外，redis 也经常⽤来做分布式锁。redis 提</p>
<p>供了多种数据类型来⽀持不同的业务场景。除此之外，redis ⽀持事务 、持久化、LUA脚本、LRU驱动</p>
<p>事件、多种集群⽅案。</p>
<p><strong>为什么要⽤</strong> redis/<strong>为什么要⽤缓存</strong></p>
<p>主要从“⾼性能”和“⾼并发”这两点来看待这个问题。</p>
<p><strong>⾼性能：</strong>假如⽤户第⼀次访问数据库中的某些数据。这个过程会⽐᫾慢，因为是从硬盘上读取的。将该⽤户访问</p>
<p>的数据存在缓存中，这样下⼀次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接</p>
<p>操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！</p>
<p><strong>⾼并发：</strong></p>
<p>直接操作缓存能够承受的请求是远远⼤于直接访问数据库的，所以我们可以考虑把数据库中的部分数据</p>
<p>转移到缓存中去，这样⽤户的⼀部分请求会直接到缓存这⾥⽽不⽤经过数据库。<strong>为什么要⽤</strong> redis <strong>⽽不⽤</strong> map/guava <strong>做缓存</strong>?</p>
<p>下⾯的内容来⾃ segmentfault ⼀位⽹友的提问，地址：<a target="_blank" rel="noopener" href="https://segmentfault.com/q/1010000009">https://segmentfault.com/q/1010000009</a></p>
<p>106416</p>
<p>缓存分为本地缓存和分布式缓存。以 Java 为例，使⽤⾃带的 map 或者 guava 实现的是本地缓存，最</p>
<p>主要的特点是轻量以及快速，⽣命周期随着 jvm 的销毁⽽结束，并且在多实例的情况下，每个实例都</p>
<p>需要各⾃保存⼀份缓存，缓存不具有⼀致性。</p>
<p>使⽤ redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共⽤⼀份缓存数据，缓</p>
<p>存具有⼀致性。缺点是需要保持 redis 或 memcached服务的⾼可⽤，整个程序架构上᫾为复杂。</p>
<p>4.2.2 redis <strong>的线程模型</strong></p>
<p>参考地址:<a target="_blank" rel="noopener" href="https://www.javazhiyin.com/22943.html">https://www.javazhiyin.com/22943.html</a></p>
<p>redis 内部使⽤⽂件事件处理器 file event handler ，这个⽂件事件处理器是单线程的，所以</p>
<p>redis 才叫做单线程的模型。它采⽤ IO 多路复⽤机制同时监听多个 socket，根据 socket 上的事件</p>
<p>来选择对应的事件处理器进⾏处理。</p>
<p>⽂件事件处理器的结构包含 4 个部分：</p>
<p>多个 socket</p>
<p>IO 多路复⽤程序</p>
<p>⽂件事件分派器</p>
<p>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）多个 socket 可能会并发产⽣不同的操作，每个操作对应不同的⽂件事件，但是 IO 多路复⽤程序会监</p>
<p>听多个 socket，会将 socket 产⽣的事件放⼊队列中排队，事件分派器每次从队列中取出⼀个事件，</p>
<p>把该事件交给对应的事件处理器进⾏处理。</p>
<p>4.2.3 redis <strong>和</strong> memcached <strong>的区别</strong></p>
<p>对于 redis 和 memcached 我总结了下⾯四点。现在公司⼀般都是⽤ redis 来实现缓存，⽽且 redis</p>
<p>⾃身也越来越强⼤了！</p>
<p>\1. <strong>redis****⽀持更丰富的数据类型（⽀持更复杂的应⽤场景）</strong>：Redis不仅仅⽀持简单的k/v类型的数</p>
<p>据，同时还提供list，set，zset，hash等数据结构的存储。memcache⽀持简单的数据类型，</p>
<p>String。</p>
<p>\2. <strong>Redis****⽀持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进⾏使</strong></p>
<p><strong>⽤</strong>**,<strong><strong>⽽</strong></strong>Memecache**<strong>把数据全部存在内存之中。</strong></p>
<p>\3. <strong>集群模式</strong>：memcached没有原⽣的集群模式，需要依靠客户端来实现往集群中分⽚写⼊数据；但</p>
<p>是 redis ⽬前是原⽣⽀持 cluster 模式的.</p>
<p>\4. <strong>Memcached<strong><strong>是多线程，⾮阻塞</strong></strong>IO<strong><strong>复⽤的⽹络模型；</strong></strong>Redis****使⽤单线程的多路</strong> <strong>IO</strong> <strong>复⽤模型。</strong></p>
<p>来⾃⽹络上的⼀张图，这⾥分享给⼤家！</p>
<p>4.2.4 redis <strong>常⻅数据结构以及使⽤场景分析</strong></p>
<p>String</p>
<p><strong>常⽤命令</strong><strong>:</strong> set,get,decr,incr,mget 等。</p>
<p>String数据结构是简单的key-value类型，value其实不仅可以是String，也可以是数字。 常规key</p>
<p>value缓存应⽤； 常规计数：微博数，粉丝数等。</p>
<p>Hash</p>
<p><strong>常⽤命令：</strong> hget,hset,hgetall 等。hash 是⼀个 string 类型的 field 和 value 的映射表，hash 特别适合⽤于存储对象，后续操作的时</p>
<p>候，你可以直接仅仅修改这个对象中的某个字段的值。 ⽐如我们可以 hash 数据结构来存储⽤户信</p>
<p>息，商品信息等等。⽐如下⾯我就⽤ hash 类型存放了我本⼈的⼀些信息：</p>
<p>List</p>
<p><strong>常⽤命令</strong><strong>:</strong> lpush,rpush,lpop,rpop,lrange等</p>
<p>list 就是链表，Redis list 的应⽤场景⾮常多，也是Redis最重要的数据结构之⼀，⽐如微博的关注</p>
<p>列表，粉丝列表，消息列表等功能都可以⽤Redis的 list 结构来实现。</p>
<p>Redis list 的实现为⼀个双向链表，即可以⽀持反向查找和遍历，更⽅便操作，不过带来了部分额外</p>
<p>的内存开销。</p>
<p>另外可以通过 lrange 命令，就是从某个元素开始读取多少个元素，可以基于 list 实现分⻚查询，这</p>
<p>个很棒的⼀个功能，基于 redis 实现简单的⾼性能分⻚，可以做类似微博那种下拉不断分⻚的东⻄</p>
<p>（⼀⻚⼀⻚的往下⾛），性能⾼。</p>
<p>Set</p>
<p><strong>常⽤命令：</strong> sadd,spop,smembers,sunion 等</p>
<p>set 对外提供的功能与list类似是⼀个列表的功能，特殊之处在于 set 是可以⾃动排重的。</p>
<p>当你需要存储⼀个列表数据，⼜不希望出现重复数据时，set是⼀个很好的选择，并且set提供了判断某</p>
<p>个成员是否在⼀个set集合内的重要接⼝，这个也是list所不能提供的。可以基于 set 轻易实现交集、</p>
<p>并集、差集的操作。</p>
<p>⽐如：在微博应⽤中，可以将⼀个⽤户所有的关注⼈存在⼀个集合中，将其所有粉丝存在⼀个集合。</p>
<p>Redis可以⾮常⽅便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程，</p>
<p>具体命令如下：</p>
<p>Sorted Set</p>
<p><strong>常⽤命令：</strong> zadd,zrange,zrem,zcard等 </p>
<p>和set相⽐，sorted set增加了⼀个权重参数score，使得集合中的元素能够按score进⾏有序排列。</p>
<p><strong>举例：</strong> 在直播系统中，实时排⾏信息包含直播间在线⽤户列表，各种礼物排⾏榜，弹幕消息（可以理</p>
<p>解为按消息维度的消息排⾏榜）等信息，适合使⽤ Redis 中的 Sorted Set 结构进⾏存储。</p>
<p>key=JavaUser293847</p>
<p>value={</p>
<p> “id”: 1,</p>
<p> “name”: “SnailClimb”,</p>
<p> “age”: 22,</p>
<p> “location”: “Wuhan, Hubei”</p>
<p>}</p>
<p>sinterstore key1 key2 key3 将交集存在key1内4.2.5 redis <strong>设置过期时间</strong></p>
<p>Redis中有个设置时间过期的功能，即对存储在 redis 数据库中的值可以设置⼀个过期时间。作为⼀个</p>
<p>缓存数据库，这是⾮常实⽤的。如我们⼀般项⽬中的 token 或者⼀些登录信息，尤其是短信验证码都</p>
<p>是有时间限制的，按照传统的数据库处理⽅式，⼀般都是⾃⼰判断过期，这样⽆疑会严重影响项⽬性</p>
<p>能。</p>
<p>我们 set key 的时候，都可以给⼀个 expire time，就是过期时间，通过过期时间我们可以指定这个</p>
<p>key 可以存活的时间。</p>
<p>如果假设你设置了⼀批 key 只能存活1个⼩时，那么接下来1⼩时后，redis是怎么对这批key进⾏删除</p>
<p>的？</p>
<p><strong>定期删除</strong>**+**<strong>惰性删除。</strong></p>
<p>通过名字⼤概就能猜出这两个删除⽅式的意思了。</p>
<p><strong>定期删除</strong>：redis默认是每隔 100ms 就<strong>随机抽取</strong>⼀些设置了过期时间的key，检查其是否过期，</p>
<p>如果过期就删除。注意这⾥是随机抽取的。为什么要随机呢？你想⼀想假如 redis 存了⼏⼗万</p>
<p>个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很⼤的负载！</p>
<p><strong>惰性删除</strong> ：定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删</p>
<p>除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存⾥，除⾮你的系统去查⼀下那</p>
<p>个 key，才会被redis给删除掉。这就是所谓的惰性删除，也是够懒的哈！</p>
<p>但是仅仅通过设置过期时间还是有问题的。我们想⼀下：如果定期删除漏掉了很多过期 key，然后你也</p>
<p>没及时去查，也就没⾛惰性删除，此时会怎么样？如果⼤量过期key堆积在内存⾥，导致redis内存块耗</p>
<p>尽了。怎么解决这个问题呢？ <strong>redis</strong> <strong>内存淘汰机制。</strong></p>
<p>4.2.6 redis <strong>内存淘汰机制</strong>(MySQL<strong>⾥有</strong>2000w<strong>数据，</strong>Redis<strong>中只存</strong>20w<strong>的数据，如何</strong></p>
<p><strong>保证</strong>Redis<strong>中的数据都是热点数据</strong>?)</p>
<p>redis 配置⽂件 redis.conf 中有相关注释，我这⾥就不贴了，⼤家可以⾃⾏查阅或者通过这个⽹址查</p>
<p>看： <a target="_blank" rel="noopener" href="http://download.redis.io/redis-stable/redis.conf">http://download.redis.io/redis-stable/redis.conf</a></p>
<p><strong>redis</strong> <strong>提供</strong> <strong>6****种数据淘汰策略：</strong></p>
<p>\1. <strong>volatile-lru</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使⽤的数</p>
<p>据淘汰</p>
<p>\2. <strong>volatile-ttl</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘</p>
<p>汰</p>
<p>\3. <strong>volatile-random</strong>：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰</p>
<p>\4. <strong>allkeys-lru</strong>：当内存不⾜以容纳新写⼊数据时，在键空间中，移除最近最少使⽤的key（这个是</p>
<p>最常⽤的）</p>
<p>\5. <strong>allkeys-random</strong>：从数据集（server.db[i].dict）中任意选择数据淘汰</p>
<p>\6. <strong>no-eviction</strong>：禁⽌驱逐数据，也就是说当内存不⾜以容纳新写⼊数据时，新写⼊操作会报错。</p>
<p>这个应该没⼈使⽤吧！</p>
<p>4.0版本后增加以下两种：</p>
<p>\7. <strong>volatile-lfu</strong>：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使⽤的数据</p>
<p>淘汰</p>
<p>\8. <strong>allkeys-lfu</strong>：当内存不⾜以容纳新写⼊数据时，在键空间中，移除最不经常使⽤的key</p>
<p><strong>备注： 关于</strong> <strong>redis</strong> <strong>设置过期时间以及内存淘汰机制，我这⾥只是简单的总结⼀下，后⾯会专⻔写⼀篇</strong></p>
<p><strong>⽂章来总结！</strong>4.2.7 redis <strong>持久化机制</strong>(<strong>怎么保证</strong> redis <strong>挂掉之后再重启数据可以进⾏恢复</strong>)</p>
<p>很多时候我们需要持久化数据也就是将内存中的数据写⼊到硬盘⾥⾯，⼤部分原因是为了之后重⽤数据</p>
<p>（⽐如重启机器、机器故障之后恢复数据），或者是为了防⽌系统故障⽽将数据备份到⼀个远程位置。</p>
<p>Redis不同于Memcached的很重⼀点就是，Redis⽀持持久化，⽽且⽀持两种不同的持久化操作。<strong>Redis****的</strong></p>
<p><strong>⼀种持久化⽅式叫快照（<strong><strong>snapshotting</strong></strong>，<strong><strong>RDB</strong></strong>），另⼀种⽅式是只追加⽂件（****append-only</strong></p>
<p><strong>file,AOF****）</strong>。这两种⽅法各有千秋，下⾯我会详细这两种持久化⽅法是什么，怎么⽤，如何选择适合⾃</p>
<p>⼰的持久化⽅法。</p>
<p><strong>快照（<strong><strong>snapshotting</strong></strong>）持久化（<strong><strong>RDB</strong></strong>）</strong></p>
<p>Redis可以通过创建快照来获得存储在内存⾥⾯的数据在某个时间点上的副本。Redis创建快照之后，可</p>
<p>以对快照进⾏备份，可以将快照复制到其他服务器从⽽创建具有相同数据的服务器副本（Redis主从结</p>
<p>构，主要⽤来提⾼Redis性能），还可以将快照留在原地以便重启服务器的时候使⽤。</p>
<p>快照持久化是Redis默认采⽤的持久化⽅式，在redis.conf配置⽂件中默认有此下配置：</p>
<p><strong>AOF<strong><strong>（</strong></strong>append-only file****）持久化</strong></p>
<p>与快照持久化相⽐，AOF持久化 的实时性更好，因此已成为主流的持久化⽅案。默认情况下Redis没有</p>
<p>开启AOF（append only file）⽅式的持久化，可以通过appendonly参数开启：</p>
<p>开启AOF持久化后每执⾏⼀条会更改Redis中的数据的命令，Redis就会将该命令写⼊硬盘中的AOF⽂件。</p>
<p>AOF⽂件的保存位置和RDB⽂件的位置相同，都是通过dir参数设置的，默认的⽂件名是</p>
<p>appendonly.aof。 </p>
<p>在Redis的配置⽂件中存在三种不同的 AOF 持久化⽅式，它们分别是：</p>
<p>save 900 1 #在900秒(15分钟)之后，如果⾄少有1个key发⽣变化，</p>
<p>Redis就会⾃动触发BGSAVE命令创建快照。</p>
<p>save 300 10 #在300秒(5分钟)之后，如果⾄少有10个key发⽣变化，</p>
<p>Redis就会⾃动触发BGSAVE命令创建快照。</p>
<p>save 60 10000 #在60秒(1分钟)之后，如果⾄少有10000个key发⽣变化，</p>
<p>Redis就会⾃动触发BGSAVE命令创建快照。</p>
<p>appendonly yes</p>
<p>appendfsync always #每次有数据修改发⽣时都会写⼊AOF⽂件,这样会严重降</p>
<p>低Redis的速度</p>
<p>appendfsync everysec #每秒钟同步⼀次，显示地将多个写命令同步到硬盘</p>
<p>appendfsync no #让操作系统决定何时进⾏同步为了兼顾数据和写⼊性能，⽤户可以考虑 appendfsync everysec选项 ，让Redis每秒同步⼀次AOF⽂</p>
<p>件，Redis性能⼏乎没受到任何影响。⽽且这样即使出现系统崩溃，⽤户最多只会丢失⼀秒之内产⽣的</p>
<p>数据。当硬盘忙于执⾏写⼊操作的时候，Redis还会优雅的放慢⾃⼰的速度以便适应硬盘的最⼤写⼊速</p>
<p>度。</p>
<p><strong>Redis 4.0</strong> <strong>对于持久化机制的优化</strong></p>
<p>Redis 4.0 开始⽀持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb</p>
<p>preamble 开启）。</p>
<p>如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF ⽂件开头。这样做的好处是可</p>
<p>以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF ⾥⾯的</p>
<p>RDB 部分是压缩格式不再是 AOF 格式，可读性᫾差。</p>
<p><strong>补充内容：****AOF</strong> <strong>重写</strong></p>
<p>AOF重写可以产⽣⼀个新的AOF⽂件，这个新的AOF⽂件和原有的AOF⽂件所保存的数据库状态⼀样，但体</p>
<p>积更⼩。</p>
<p>AOF重写是⼀个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序⽆须对现有AOF⽂件</p>
<p>进⾏任何读⼊、分析或者写⼊操作。</p>
<p>在执⾏ BGREWRITEAOF 命令时，Redis 服务器会维护⼀个 AOF 重写缓冲区，该缓冲区会在⼦进程创建</p>
<p>新AOF⽂件期间，记录服务器执⾏的所有写命令。当⼦进程完成创建新AOF⽂件的⼯作之后，服务器会将</p>
<p>重写缓冲区中的所有内容追加到新AOF⽂件的末尾，使得新旧两个AOF⽂件所保存的数据库状态⼀致。最</p>
<p>后，服务器⽤新的AOF⽂件替换旧的AOF⽂件，以此来完成AOF⽂件重写操作</p>
<p><strong>更多内容可以查看我的这篇⽂章：</strong></p>
<p>Redis持久化</p>
<p>4.2.8 redis <strong>事务</strong></p>
<p>Redis 通过 MULTI、EXEC、WATCH 等命令来实现事务(transaction)功能。事务提供了⼀种将多个命令</p>
<p>请求打包，然后⼀次性、按顺序地执⾏多个命令的机制，并且在事务执⾏期间，服务器不会中断事务⽽</p>
<p>改去执⾏其他客户端的命令请求，它会将事务中的所有命令都执⾏完毕，然后才去处理其他客户端的命</p>
<p>令请求。</p>
<p>在传统的关系式数据库中，常常⽤ ACID 性质来检验事务功能的可靠性和安全性。在 Redis 中，事务</p>
<p>总是具有原⼦性（Atomicity）、⼀致性（Consistency）和隔离性（Isolation），并且当 Redis 运⾏</p>
<p>在某种特定的持久化模式下时，事务也具有持久性（Durability）。</p>
<p>补充内容：</p>
<p>\1. redis同⼀个事务中如果有⼀条命令执⾏失败，其后的命令仍然会被执⾏，没有回滚。（来⾃</p>
<p>issue:关于Redis事务不是原⼦性问题 ）</p>
<p>4.2.9 <strong>缓存雪崩和缓存穿透问题解决⽅案</strong></p>
<p><strong>缓存雪崩</strong></p>
<p><strong>什么是缓存雪崩？</strong></p>
<p>简介：缓存同⼀时间⼤⾯积的失效，所以，后⾯的请求都会落到数据库上，造成数据库短时间内承受⼤</p>
<p>量请求⽽崩掉。<strong>有哪些解决办法？</strong></p>
<p>（中华⽯杉⽼师在他的视频中提到过，视频地址在最后⼀个问题中有提到）：</p>
<p>事前：尽量保证整个 redis 集群的⾼可⽤性，发现机器宕机尽快补上。选择合适的内存淘汰策</p>
<p>略。</p>
<p>事中：本地ehcache缓存 + hystrix限流&amp;降级，避免MySQL崩掉</p>
<p>事后：利⽤ redis 持久化机制保存的数据尽快恢复缓存</p>
<p><strong>缓存穿透</strong></p>
<p><strong>什么是缓存穿透？</strong></p>
<p>缓存穿透说简单点就是⼤量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有</p>
<p>经过缓存这⼀层。举个例⼦：某个⿊客故意制造我们缓存中不存在的 key 发起⼤量请求，导致⼤量请</p>
<p>求落到数据库。下⾯⽤图⽚展示⼀下(这两张图⽚不是我画的，为了省事直接在⽹上找的，这⾥说明⼀</p>
<p>下)：</p>
<p><strong>正常缓存处理流程：****缓存穿透情况处理流程：</strong>⼀般MySQL 默认的最⼤连接数在 150 左右，这个可以通过 show variables like</p>
<p>‘%max_connections%’; 命令来查看。最⼤连接数⼀个还只是⼀个指标，cpu，内存，磁盘，⽹络等</p>
<p>⽆⼒条件都是其运⾏指标，这些指标都会限制其并发能⼒！所以，⼀般 3000 个并发请求就能打死⼤部</p>
<p>分数据库了。</p>
<p><strong>有哪些解决办法？</strong></p>
<p>最基本的就是⾸先做好参数校验，⼀些不合法的参数请求直接抛出异常信息返回给客户端。⽐如查询的</p>
<p>数据库 id 不能⼩于 0、传⼊的邮箱格式不对的时候直接返回错误消息给客户端等等。</p>
<p><strong>1****）缓存⽆效</strong> <strong>key</strong> : 如果缓存和数据库都查不到某个 key 的数据就写⼀个到 redis 中去并设置过期时</p>
<p>间，具体命令如下： SET key value EX 10086 。这种⽅式可以解决请求的 key 变化不频繁的情</p>
<p>况，如果⿊客恶意攻击，每次构建不同的请求key，会导致 redis 中缓存⼤量⽆效的 key 。很明显，</p>
<p>这种⽅案并不能从根本上解决此问题。如果⾮要⽤这种⽅式来解决穿透问题的话，尽量将⽆效的 key</p>
<p>的过期时间设置短⼀点⽐如 1 分钟。</p>
<p>另外，这⾥多说⼀嘴，⼀般情况下我们是这样设计 key 的： 表名:列名:主键名:主键值 。</p>
<p>如果⽤ Java 代码展示的话，差不多是下⾯这样的：</p>
<p>public Object getObjectInclNullById(Integer id) {</p>
<p> // 从缓存中获取数据</p>
<p> Object cacheValue = cache.get(id);</p>
<p> // 缓存为空</p>
<p> if (cacheValue WX null) {</p>
<p> // 从数据库中获取</p>
<p> Object storageValue = storage.get(key);</p>
<p> // 缓存空对象</p>
<p> cache.set(key, storageValue);</p>
<p> // 如果存储数据为空，需要设置⼀个过期时间(300秒)</p>
<p> if (storageValue WX null) {</p>
<p> // 必须设置过期时间，否则有被攻击的⻛险</p>
<p> cache.expire(key, 60 * 5);</p>
<p> }</p>
<p> return storageValue;</p>
<p> }</p>
<p> return cacheValue; </p>
<p>} </p>
<p><strong>2****）布隆过滤器：</strong>布隆过滤器是⼀个⾮常神奇的数据结构，通过它我们可以⾮常⽅便地判断⼀个给定数</p>
<p>据是否存在与海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要</p>
<p>找的那个“⼈”。具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当⽤户请求过</p>
<p>来，我会先判断⽤户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信</p>
<p>息给客户端，存在的话才会⾛下⾯的流程。总结⼀下就是下⾯这张图(这张图⽚不是我画的，为了省事</p>
<p>直接在⽹上找的)：更多关于布隆过滤器的内容可以看我的这篇原创：《不了解布隆过滤器？⼀⽂给你整的明明⽩⽩！》</p>
<p>，强烈推荐，个⼈感觉⽹上应该找不到总结的这么明明⽩⽩的⽂章了。</p>
<p>4.2.10 <strong>如何解决</strong> Redis <strong>的并发竞争</strong> Key <strong>问题</strong></p>
<p>所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对⼀个 key 进⾏操作，但是最后执⾏的顺序</p>
<p>和我们期望的顺序不同，这样也就导致了结果的不同！</p>
<p>推荐⼀种⽅案：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发</p>
<p>竞争 Key 问题，不要使⽤分布式锁，这样会影响性能）</p>
<p>基于zookeeper临时有序节点可以实现的分布式锁。⼤致思想为：每个客户端对某个⽅法加锁时，在</p>
<p>zookeeper上的与该⽅法对应的指定节点的⽬录下，⽣成⼀个唯⼀的瞬时有序节点。 判断是否获取锁的</p>
<p>⽅式很简单，只需要判断有序节点中序号最⼩的⼀个。 当释放锁的时候，只需将这个瞬时节点删除即</p>
<p>可。同时，其可以避免服务宕机导致的锁⽆法释放，⽽产⽣的死锁问题。完成业务流程后，删除对应的</p>
<p>⼦节点释放锁。</p>
<p>在实践中，当然是从以可靠性为主。所以⾸推Zookeeper。</p>
<p>参考：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/8bddd381de06">https://www.jianshu.com/p/8bddd381de06</a></p>
<p>4.2.11 <strong>如何保证缓存与数据库双写时的数据⼀致性</strong>?</p>
<p>⼀般情况下我们都是这样使⽤缓存的：先读缓存，缓存没有的话，就读数据库，然后取出数据后放</p>
<p>⼊缓存，同时返回响应。这种⽅式很明显会存在缓存和数据库的数据不⼀致的情况。</p>
<p>你只要⽤缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就⼀定会有数据⼀致性的问</p>
<p>题，那么你如何解决⼀致性问题？</p>
<p>⼀般来说，就是如果你的系统不是严格要求缓存+数据库必须⼀致性的话，缓存可以稍微的跟数据库偶</p>
<p>尔有不⼀致的情况，最好不要做这个⽅案，读请求和写请求串⾏化，串到⼀个内存队列⾥去，这样就可</p>
<p>以保证⼀定不会出现不⼀致的情况</p>
<p>串⾏化之后，就会导致系统的吞吐量会⼤幅度的降低，⽤⽐正常情况下多⼏倍的机器去⽀撑线上的⼀个</p>
<p>请求。</p>
<p>更多内容可以查看：<a target="_blank" rel="noopener" href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency">https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency</a></p>
<p>/redis-consistence.md</p>
<p><strong>参考：</strong> Java⼯程师⾯试突击第1季（可能是史上最好的Java⾯试突击课程）-中华⽯杉⽼师！公众号后</p>
<p>台回复关键字“1”即可获取该视频内容。</p>
<p><strong>参考</strong></p>
<p>《Redis开发与运维》</p>
<p>Redis 命令总结：<a target="_blank" rel="noopener" href="http://redisdoc.com/string/set.html">http://redisdoc.com/string/set.html</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">chen-boran</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2022/02/11/Redis%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/">http://example.com/2022/02/11/Redis%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Redis/">Redis</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202203151833185.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/02/12/MySQL%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95-%E7%B4%A2%E5%BC%95%E4%B8%8E%E7%AE%97%E6%B3%95/"><img class="prev-cover" src="https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202203151833187.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">MySQL技术内幕-索引与算法</div></div></a></div><div class="next-post pull-right"><a href="/2021/11/25/mysql%E5%85%A8%E6%96%87%E6%9C%AC%E6%90%9C%E7%B4%A2/"><img class="next-cover" src="https://ae01.alicdn.com/kf/H0bd119c4d36e49a8984678f0b7b6f942R.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">mysql全文本搜索</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2021/11/17/Redis-Sentinel/" title="Redis Sentinel"><img class="cover" src="https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202203151833185.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-11-17</div><div class="title">Redis Sentinel</div></div></a></div><div><a href="/2021/11/11/Redis-事件驱动模型/" title="Redis 事件驱动模型"><img class="cover" src="https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202203151833185.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-11-11</div><div class="title">Redis 事件驱动模型</div></div></a></div><div><a href="/2021/11/15/Redis-复制/" title="Redis 复制"><img class="cover" src="https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202203151833185.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-11-15</div><div class="title">Redis 复制</div></div></a></div><div><a href="/2021/11/14/Redis-持久化/" title="Redis 持久化"><img class="cover" src="https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202203151833185.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-11-14</div><div class="title">Redis 持久化</div></div></a></div><div><a href="/2022/03/17/Redis-慢查询日志/" title="Redis-慢查询日志"><img class="cover" src="https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202203151833187.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-17</div><div class="title">Redis-慢查询日志</div></div></a></div><div><a href="/2021/11/14/Redis-数据库/" title="Redis 数据库"><img class="cover" src="https://cdn.jsdelivr.net/gh/chen-boran/Picture_bed/img/202203151833185.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-11-14</div><div class="title">Redis 数据库</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/favicon.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">chen-boran</div><div class="author-info__description">I want to roll the sky desperately!</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">56</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">12</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/chen_boran"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-5%E5%85%B6%E4%BB%96%E4%BF%9D%E9%9A%9C%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E7%9A%84%E6%96%B9%E6%A1%88%E4%B8%8E%E8%B5%84%E6%96%99"><span class="toc-text">3.5其他保障数据一致的方案与资料</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/04/19/Computer-network-Summery-of-basic/" title="No title"><img src="https://ae01.alicdn.com/kf/H0bd119c4d36e49a8984678f0b7b6f942R.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"/></a><div class="content"><a class="title" href="/2022/04/19/Computer-network-Summery-of-basic/" title="No title">No title</a><time datetime="2022-04-19T11:37:37.941Z" title="Created 2022-04-19 19:37:37">2022-04-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/04/16/JavaEE-%E5%AD%97%E7%AC%A6%E4%B8%B2/" title="No title"><img src="https://ae01.alicdn.com/kf/H0bd119c4d36e49a8984678f0b7b6f942R.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"/></a><div class="content"><a class="title" href="/2022/04/16/JavaEE-%E5%AD%97%E7%AC%A6%E4%B8%B2/" title="No title">No title</a><time datetime="2022-04-16T07:31:53.335Z" title="Created 2022-04-16 15:31:53">2022-04-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/04/16/JavaEE-%E5%BC%82%E5%B8%B8/" title="No title"><img src="https://ae01.alicdn.com/kf/H0bd119c4d36e49a8984678f0b7b6f942R.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"/></a><div class="content"><a class="title" href="/2022/04/16/JavaEE-%E5%BC%82%E5%B8%B8/" title="No title">No title</a><time datetime="2022-04-16T07:31:53.282Z" title="Created 2022-04-16 15:31:53">2022-04-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/04/16/JavaEE-%E6%9E%9A%E4%B8%BE/" title="No title"><img src="https://ae01.alicdn.com/kf/H0bd119c4d36e49a8984678f0b7b6f942R.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"/></a><div class="content"><a class="title" href="/2022/04/16/JavaEE-%E6%9E%9A%E4%B8%BE/" title="No title">No title</a><time datetime="2022-04-16T07:31:53.255Z" title="Created 2022-04-16 15:31:53">2022-04-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/04/16/JavaEE-%E9%9B%86%E5%90%88/" title="No title"><img src="https://ae01.alicdn.com/kf/H0bd119c4d36e49a8984678f0b7b6f942R.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"/></a><div class="content"><a class="title" href="/2022/04/16/JavaEE-%E9%9B%86%E5%90%88/" title="No title">No title</a><time datetime="2022-04-16T07:31:53.218Z" title="Created 2022-04-16 15:31:53">2022-04-16</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By chen-boran</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="/js/randombg.js"></script><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><script src="/clock/js/clock.js"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" data-mobile="false" data-text="人的梦想,是不会终结的！,绝对不会再输！,人,最重要的是心啊~" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start -->
  <script data-pjax src="https://cdn.jsdelivr.net/gh/zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?chen-boran";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="chen-boran";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:280px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script data-pjax>
  function butterfly_clock_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src="https://npm.elemecdn.com/hexo-butterfly-clock/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_injector_config();
  }
  </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax src="https://npm.elemecdn.com/hexo-butterfly-clock/lib/clock.min.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-wanko"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body></html>